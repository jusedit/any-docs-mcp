{
  "project_meta": {
    "name": "anydocs-mcp-quality-upgrade",
    "version": "1.0.0",
    "ralph_type": "opencode",
    "opencode_session_id": "quality-retrieval-upgrade-v1"
  },
  "backlog": [
    {
      "group": "Test-Harness-Fixtures",
      "feature": "Python test infrastructure with pytest",
      "description": "Add pytest to scraper/requirements.txt, create scraper/tests/ directory with conftest.py, and a trivial smoke test that imports all scraper modules. This is the foundation — every subsequent PR runs these tests.",
      "acceptance_criteria": [
        "pytest listed in requirements.txt — verify: pip install -r requirements.txt succeeds",
        "scraper/tests/__init__.py and scraper/tests/conftest.py exist",
        "Smoke test scraper/tests/test_imports.py imports ContentCleaner, ScraperEngine, StorageManager, URLDiscovery, GitHubDiscovery, SitemapParser, SiteAnalysis — verify: python -m pytest scraper/tests/test_imports.py -v passes",
        "conftest.py provides a tmp_path-based fixture 'tmp_storage' that returns a StorageManager rooted in a temp dir"
      ],
      "passes": true
    },
    {
      "group": "Test-Harness-Fixtures",
      "feature": "TypeScript test infrastructure with vitest",
      "description": "Add vitest as devDependency to mcp-server, configure vitest.config.ts, add a 'test' script to package.json, and create a trivial smoke test that imports MarkdownParser and config helpers.",
      "acceptance_criteria": [
        "vitest in devDependencies — verify: npm install succeeds",
        "package.json has 'test': 'vitest run' script",
        "vitest.config.ts exists with ESM support and src/ root",
        "mcp-server/src/__tests__/imports.test.ts imports MarkdownParser, loadConfig — verify: npm test passes"
      ],
      "passes": true
    },
    {
      "group": "Test-Harness-Fixtures",
      "feature": "Golden HTML fixtures for content extraction",
      "description": "Create tests/fixtures/html/ directory with 3 representative saved HTML pages: (1) a VitePress-style doc page, (2) a Docusaurus-style doc page, (3) a raw GitHub markdown page. Each fixture is a static .html file (no network required). These are the inputs for deterministic content_cleaner and scraper_engine tests.",
      "acceptance_criteria": [
        "tests/fixtures/html/vitepress-sample.html exists (~5-15 KB, realistic structure with nav, content, code blocks)",
        "tests/fixtures/html/docusaurus-sample.html exists (different selectors, sidebar, code tabs)",
        "tests/fixtures/html/github-raw-markdown.html exists (raw markdown wrapped in the raw-markdown div as scraper_engine produces)",
        "Each fixture has a companion .meta.json with expected content_selectors and expected title",
        "No network calls needed to use fixtures — verify: files exist and are valid HTML"
      ],
      "passes": true
    },
    {
      "group": "Test-Harness-Fixtures",
      "feature": "Golden Markdown output fixtures for snapshot testing",
      "description": "For each HTML fixture, create a corresponding expected-output .md file in tests/fixtures/expected/. These are the 'golden files' that content extraction results are compared against. Add a pytest test that extracts content from each HTML fixture and compares to the golden output (with a configurable tolerance for whitespace).",
      "acceptance_criteria": [
        "tests/fixtures/expected/vitepress-sample.md exists with clean expected markdown",
        "tests/fixtures/expected/docusaurus-sample.md exists",
        "tests/fixtures/expected/github-raw-markdown.md exists",
        "scraper/tests/test_content_extraction.py loads each HTML fixture, runs extract_content + content_cleaner.clean, and asserts output matches golden .md file — verify: pytest scraper/tests/test_content_extraction.py -v passes",
        "Comparison ignores trailing whitespace differences but catches structural changes (headings, code blocks, content loss)"
      ],
      "passes": true
    },
    {
      "group": "Test-Harness-Fixtures",
      "feature": "Golden search query suite for MarkdownParser",
      "description": "Create tests/fixtures/search/ with a small markdown doc set (2-3 .md files with known sections, code blocks, headings). Create a query-suite.json defining 10 queries with expected top-1 section titles. Add a vitest test that builds the index and verifies each query returns the expected top result.",
      "acceptance_criteria": [
        "tests/fixtures/search/test-docs/ contains 2-3 small .md files with diverse headings and code blocks",
        "tests/fixtures/search/query-suite.json has 10 entries: {query, expectedTopTitle, expectedFile}",
        "mcp-server/src/__tests__/search-golden.test.ts builds index from fixture docs and asserts top-1 result matches expected — verify: npm test passes",
        "At least 8/10 queries pass (allows 2 to be marked 'aspirational' for future search improvements)"
      ],
      "passes": true
    },
    {
      "group": "Source-Selection-Routing",
      "feature": "Detect raw markdown availability before HTML scraping",
      "description": "In scraper_engine.py, before calling markdownify on HTML, check if the page's content is already available as raw markdown (e.g., raw.githubusercontent.com URLs, or pages serving text/markdown content-type). If raw markdown is available, skip HTML-to-MD conversion entirely and use the raw content. Currently raw GitHub content is detected by URL substring in fetch_page; refactor this into an explicit SourceType enum (RAW_MARKDOWN, HTML) returned alongside the soup.",
      "acceptance_criteria": [
        "New enum SourceType with values RAW_MARKDOWN and HTML in models.py — verify: import works",
        "fetch_page returns a tuple (soup, source_type) instead of just soup — verify: all callers updated",
        "extract_content checks source_type: if RAW_MARKDOWN, returns raw text directly without markdownify — verify: test with GitHub raw fixture",
        "Existing HTML extraction path unchanged for source_type=HTML — verify: test with VitePress fixture",
        "scraper/tests/test_source_routing.py tests both paths with fixtures — verify: pytest passes"
      ],
      "passes": true
    },
    {
      "group": "Source-Selection-Routing",
      "feature": "Content-Type header sniffing for markdown sources",
      "description": "Extend fetch_page to inspect the HTTP Content-Type header. If it's text/markdown or text/x-markdown, treat the response as RAW_MARKDOWN even if the URL doesn't contain 'raw.githubusercontent.com'. This makes the 'prefer markdown' strategy work for any server that correctly sets Content-Type.",
      "acceptance_criteria": [
        "fetch_page checks response.headers['Content-Type'] for 'text/markdown' or 'text/x-markdown' — verify: code inspection",
        "When Content-Type indicates markdown, source_type is RAW_MARKDOWN — verify: unit test with mocked response",
        "URL-based detection (raw.githubusercontent.com) remains as fallback — verify: existing GitHub tests still pass",
        "scraper/tests/test_source_routing.py extended with Content-Type test — verify: pytest passes"
      ],
      "passes": false
    },
    {
      "group": "Source-Selection-Routing",
      "feature": "GitHub discovery: prefer raw markdown URLs over HTML scraping",
      "description": "Ensure GitHubDiscovery always returns raw.githubusercontent.com URLs (it already does). Add a unit test for discover_markdown_files that verifies all returned URLs start with raw.githubusercontent.com and that the repo tree API response is correctly parsed. Use a saved JSON fixture of a GitHub API tree response instead of hitting the real API.",
      "acceptance_criteria": [
        "tests/fixtures/github/tree-response.json contains a realistic GitHub API tree response (20-30 items, mix of .md and non-.md) — verify: file exists",
        "scraper/tests/test_github_discovery.py mocks requests.get to return the fixture and asserts: only .md files returned, all URLs start with raw.githubusercontent.com, priority sorting works — verify: pytest passes",
        "Test also covers the is_github_repo detection for various URL formats — verify: parametrized test with 5+ URLs"
      ],
      "passes": true
    },
    {
      "group": "Source-Selection-Routing",
      "feature": "Graceful fallback when raw markdown extraction fails",
      "description": "If a RAW_MARKDOWN source returns empty or very short content (<50 chars after stripping), fall back to HTML extraction for that page. Log a warning. This prevents silent data loss when a raw source is unexpectedly empty.",
      "acceptance_criteria": [
        "If raw markdown content after strip is <50 chars, re-fetch as HTML and run normal extraction — verify: test with near-empty raw fixture",
        "Warning logged to stderr when fallback triggers — verify: captured log in test",
        "Normal raw markdown (>50 chars) is NOT re-fetched — verify: test with valid raw fixture shows no double fetch",
        "scraper/tests/test_source_routing.py extended — verify: pytest passes"
      ],
      "passes": true
    },
    {
      "group": "HTML-Markdown-Quality",
      "feature": "Preserve heading hierarchy in markdownify output",
      "description": "Current markdownify usage sometimes produces flat headings (all ##) or skips levels. Add a post-processing step in content_cleaner that normalizes heading levels: ensure the first heading is # or ##, and child headings increment by exactly 1 level. This makes the MarkdownParser's section tree accurate.",
      "acceptance_criteria": [
        "New method ContentCleaner.normalize_heading_levels(content) that fixes heading hierarchy — verify: unit test",
        "Heading levels never skip (no jump from ## to ####) — verify: regex assertion on output",
        "First heading in extracted content is level 1 or 2 — verify: test with VitePress fixture where first heading might be h3",
        "clean() method calls normalize_heading_levels before normalize_whitespace — verify: code inspection",
        "scraper/tests/test_content_cleaner.py tests heading normalization with 3 edge cases — verify: pytest passes"
      ],
      "passes": true
    },
    {
      "group": "HTML-Markdown-Quality",
      "feature": "Improve HTML table to markdown conversion",
      "description": "markdownify's default table handling often produces broken markdown tables (missing alignment row, merged cells lost). Add a pre-processing step that detects <table> elements and converts them to clean markdown tables before markdownify runs. Handle common cases: simple data tables, header rows, and tables without <thead>.",
      "acceptance_criteria": [
        "New method ContentCleaner.fix_markdown_tables(content) that repairs broken table output — verify: unit test",
        "Simple 2-column tables render as valid markdown with header separator row — verify: test with fixture containing API parameter table",
        "Tables without <thead> use first row as header — verify: test case",
        "Tables with >6 columns are preserved but not mangled — verify: test case",
        "scraper/tests/test_content_cleaner.py extended with table tests — verify: pytest passes",
        "Golden output fixtures updated to reflect improved table rendering — verify: snapshot tests still pass"
      ],
      "passes": true
    },
    {
      "group": "HTML-Markdown-Quality",
      "feature": "Improve code block extraction and language detection",
      "description": "Current code_language_callback in scraper_engine.py only checks el.get('class')[0]. Many sites use data-language, data-lang, or nested <code class='language-xxx'> inside <pre>. Extend the callback to check multiple attributes. Also improve ContentCleaner._auto_detect_code_language to handle more edge cases (Go, Rust, YAML, TOML, Dockerfile).",
      "acceptance_criteria": [
        "code_language_callback checks: class='language-xxx', data-language, data-lang, data-code-language attributes — verify: test with Docusaurus fixture (uses data-language)",
        "ContentCleaner._auto_detect_code_language handles Go (func main, package), Rust (fn main, let mut), YAML (key: value indentation), TOML ([section]), Dockerfile (FROM, RUN) — verify: parametrized unit test with 5 new languages",
        "Existing language detection (JS, Python, Bash, HTML, CSS, JSON, SQL) unchanged — verify: regression test",
        "scraper/tests/test_content_cleaner.py extended — verify: pytest passes"
      ],
      "passes": true
    },
    {
      "group": "HTML-Markdown-Quality",
      "feature": "Remove site-specific noise patterns",
      "description": "Extend ContentCleaner.UI_ARTIFACT_PATTERNS with patterns observed from real scrapes: Algolia search widgets, cookie consent banners, 'On this page' TOC blocks, breadcrumb trails, and version switcher dropdowns. Make the pattern list configurable via an optional parameter so site-specific patterns can be added.",
      "acceptance_criteria": [
        "At least 10 new UI_ARTIFACT_PATTERNS added covering: Algolia, cookie banners, TOC sidebars, breadcrumbs, version switchers — verify: code inspection",
        "ContentCleaner.__init__ accepts optional extra_patterns list that extends the defaults — verify: unit test",
        "Existing patterns still work — verify: regression test on current fixtures",
        "New patterns tested with at least 2 fixture snippets containing the artifacts — verify: pytest passes",
        "Golden output fixtures updated if affected — verify: snapshot tests pass"
      ],
      "passes": true
    },
    {
      "group": "HTML-Markdown-Quality",
      "feature": "Content deduplication within a single doc set",
      "description": "Some sites include the same content block on multiple pages (e.g., footer text, shared warnings). When assembling pages into a grouped markdown file, detect and skip duplicate content blocks (>100 chars, appearing in 3+ pages). Use content hashing for efficient comparison.",
      "acceptance_criteria": [
        "New method ScraperEngine._deduplicate_content(content, seen_hashes) that removes paragraphs appearing in 3+ pages — verify: unit test",
        "Deduplication operates on paragraph-level blocks (split by double newline), not individual lines — verify: test",
        "Short blocks (<100 chars) are excluded from dedup to avoid removing common headings — verify: test",
        "Hash-based comparison (MD5 of stripped paragraph) for O(1) lookup — verify: code inspection",
        "scraper/tests/test_deduplication.py tests with synthetic multi-page content — verify: pytest passes"
      ],
      "passes": true
    },
    {
      "group": "Search-Relevance",
      "feature": "Query-suite evaluation harness with precision metrics",
      "description": "Create a reusable search evaluation harness that loads a query-suite JSON, runs each query against a MarkdownParser index, and reports precision@1, precision@3, and MRR (Mean Reciprocal Rank). Output a structured JSON report. This harness is the foundation for measuring all search improvements objectively.",
      "acceptance_criteria": [
        "mcp-server/src/__tests__/search-eval.ts exports function evaluateQuerySuite(parser, suite) returning {precision1, precision3, mrr, details[]} — verify: unit test",
        "details[] includes per-query: {query, expectedTitle, actualTitles[], hit, rank} — verify: test output inspection",
        "MRR computed correctly: 1/rank for first correct result, 0 if not in top-10 — verify: manual calculation on fixture",
        "search-golden.test.ts rewritten to use evaluateQuerySuite and assert precision@1 >= 0.8 — verify: npm test passes",
        "Report output is JSON-serializable for CI artifact storage — verify: JSON.stringify test"
      ],
      "passes": true
    },
    {
      "group": "Search-Relevance",
      "feature": "TF-IDF-inspired term weighting in search scoring",
      "description": "Current search scores each term occurrence equally (2 points per match, capped at 20). Implement IDF-inspired weighting: rare terms across the corpus get higher weight than common terms. This requires a term-frequency map built during indexing. Keeps the algorithm simple (no external dependencies) but significantly improves relevance for multi-word queries.",
      "acceptance_criteria": [
        "MarkdownParser.buildIndex() now computes a Map<string, number> termDocumentFrequency counting how many sections contain each term — verify: test index has expected df values",
        "search() uses idf = log(totalSections / df) to weight term matches — verify: code inspection",
        "Rare terms (appearing in <5% of sections) score higher than common terms (appearing in >50%) — verify: test with contrived corpus",
        "Exact title match bonus (100 points) unchanged — verify: regression test",
        "Query suite precision@1 stays >= 0.8 (should improve) — verify: search-golden.test.ts passes"
      ],
      "passes": true
    },
    {
      "group": "Search-Relevance",
      "feature": "Stemming-lite for search terms",
      "description": "Implement a minimal English stemmer (suffix stripping only: -ing, -tion, -ed, -s, -ly, -er, -est, -ment) that normalizes both query terms and indexed content during search. No external library — just a 20-line function. This helps queries like 'configuring' match sections titled 'Configuration'.",
      "acceptance_criteria": [
        "New function simpleStem(word) in markdown-parser.ts that strips common suffixes — verify: unit test with 15+ word pairs",
        "search() applies simpleStem to both query terms and section content during scoring — verify: code inspection",
        "Stemming is applied only to terms >4 characters to avoid mangling short words — verify: test",
        "'configuring' matches 'Configuration', 'installing' matches 'Installation' — verify: query suite test cases added",
        "No false positives from over-stemming (e.g., 'string' should not become 'str') — verify: negative test cases",
        "Query suite precision@1 stays >= 0.8 — verify: npm test passes"
      ],
      "passes": true
    },
    {
      "group": "Search-Relevance",
      "feature": "Boost sections with code blocks matching query terms",
      "description": "Current code block scoring gives a flat +15 per term found in any code block. Improve this: if query terms appear in code blocks AND the section title, apply a multiplier. Also boost sections that have code blocks in the query's likely programming language (detect from query context).",
      "acceptance_criteria": [
        "Code block + title match combo gets 2x multiplier on the code block score — verify: test with fixture",
        "Sections with 3+ code blocks get a small diversity bonus (+5) as they're likely tutorial/example sections — verify: test",
        "Total code block contribution still capped (at 40 instead of 15) to prevent score domination — verify: code inspection",
        "Query suite updated with 2 code-focused queries (e.g., 'useState example', 'fetch API code') — verify: expected results defined",
        "Overall precision@1 stays >= 0.8 — verify: npm test passes"
      ],
      "passes": true
    },
    {
      "group": "Performance-Observability",
      "feature": "Search benchmark harness with p50/p95 reporting",
      "description": "Create a vitest benchmark that runs 50 search queries against the fixture doc set, measures wall-clock time per query, and reports p50 and p95 latencies. Assert p95 < 200ms as a regression gate. Output results as JSON for CI artifact collection.",
      "acceptance_criteria": [
        "mcp-server/src/__tests__/search-bench.test.ts runs 50 queries (mix of single-term, multi-term, exact title) — verify: npm test passes",
        "Reports p50 and p95 latency in milliseconds to stderr — verify: output inspection",
        "Asserts p95 < 200ms on fixture doc set — verify: test passes",
        "Writes benchmark-results.json to test output dir with {p50, p95, mean, max, queryCount} — verify: file is valid JSON",
        "Benchmark uses performance.now() for high-resolution timing — verify: code inspection"
      ],
      "passes": false
    },
    {
      "group": "Performance-Observability",
      "feature": "Index build time measurement and regression gate",
      "description": "Add timing instrumentation to MarkdownParser.buildIndex(). Log the time taken to stderr. In the benchmark test, assert index build time < 5 seconds for the fixture doc set (and < 30 seconds as a loose gate for large doc sets up to 200 files).",
      "acceptance_criteria": [
        "buildIndex() logs 'Index built in Xms (Y sections from Z files)' to stderr — verify: log output test",
        "Build time available via a public getter: parser.lastBuildTimeMs — verify: vitest test reads it",
        "Benchmark test asserts build time < 5000ms for fixture set — verify: npm test passes",
        "No performance regression for large doc sets — verify: test with 100-file synthetic fixture stays < 10s"
      ],
      "passes": false
    },
    {
      "group": "Performance-Observability",
      "feature": "Scraper progress events structured logging",
      "description": "Standardize the scraper's progress output. Currently _report_progress writes JSON to stdout (PROGRESS:{...}) and unstructured text to stderr. Ensure all progress events go through a single structured logger that writes JSONL (one JSON object per line) to a configurable stream. This makes CI parsing trivial and enables future dashboards.",
      "acceptance_criteria": [
        "New class ProgressLogger in scraper/progress_logger.py with methods: start, update, complete, fail — verify: import test",
        "Each method writes a single JSON line with {timestamp, phase, current, total, url, message} — verify: unit test captures output",
        "ScraperEngine uses ProgressLogger instead of direct print/json.dumps calls — verify: code inspection shows all _report_progress calls delegate to ProgressLogger",
        "Legacy PROGRESS: prefix retained for backward compat with MCP server's stdout parser — verify: MCP server can still parse progress",
        "scraper/tests/test_progress_logger.py verifies JSONL output format — verify: pytest passes"
      ],
      "passes": false
    },
    {
      "group": "Performance-Observability",
      "feature": "Content extraction quality metrics",
      "description": "After scraping a doc set, compute and log quality metrics: average content length per page, percentage of pages with code blocks, percentage of pages with <100 chars (likely extraction failures), heading count distribution. Store metrics in metadata.json alongside existing fields.",
      "acceptance_criteria": [
        "ScraperEngine.scrape_all() computes metrics dict: {avg_content_length, pages_with_code_blocks, pages_below_100_chars, avg_headings_per_page} — verify: test with synthetic pages",
        "Metrics stored in metadata.json under 'quality_metrics' key — verify: metadata fixture inspection",
        "pages_below_100_chars > 20% triggers a warning log — verify: test with mostly-empty pages",
        "list_documentation_sets MCP tool displays quality_metrics.pages_below_100_chars if > 0 — verify: manual inspection",
        "scraper/tests/test_quality_metrics.py tests metric computation — verify: pytest passes"
      ],
      "passes": false
    },
    {
      "group": "MCP-E2E-Integration",
      "feature": "MCP server stdio E2E test harness",
      "description": "Create a vitest E2E test that spawns the MCP server as a child process (node dist/index.js), sends JSON-RPC requests via stdin, and asserts responses on stdout. This replaces the manual test-mcp.ts script with an automated, CI-friendly approach. Uses a fixture doc set in a temp directory pointed to via ANYDOCS_STORAGE_ROOT.",
      "acceptance_criteria": [
        "mcp-server/src/__tests__/e2e-mcp.test.ts spawns the server with env ANYDOCS_STORAGE_ROOT pointing to a fixture doc set — verify: npm test passes",
        "Test sends 'initialize' handshake, then 'tools/list' and asserts all 12 tools are present — verify: assertion on tool count",
        "Test calls 'tools/call' with search tool and asserts response contains results — verify: result content check",
        "Server process is killed in afterAll() — verify: no orphan processes",
        "Test timeout set to 15s to account for index build — verify: test config inspection"
      ],
      "passes": true
    },
    {
      "group": "MCP-E2E-Integration",
      "feature": "E2E test: switch_documentation tool",
      "description": "Extend E2E test to cover the switch_documentation flow: start with no active docs, call list_documentation_sets to verify fixture sets are visible, call switch_documentation to activate one, then search to verify the index was rebuilt.",
      "acceptance_criteria": [
        "Fixture directory contains 2 doc sets (test-docs-a and test-docs-b) each with config.json, metadata.json, and a v1/ with .md files — verify: fixture structure",
        "E2E test calls list_documentation_sets and asserts both sets are listed — verify: response parsing",
        "E2E test calls switch_documentation to test-docs-a, then search returns results from docs-a only — verify: file field in results",
        "E2E test switches to test-docs-b and verifies search now returns docs-b results — verify: file field changed",
        "mcp-server/src/__tests__/e2e-switch.test.ts passes — verify: npm test"
      ],
      "passes": true
    },
    {
      "group": "MCP-E2E-Integration",
      "feature": "E2E test: get_overview and get_file_toc tools",
      "description": "Add E2E tests for get_overview (returns file list with top-level sections) and get_file_toc (returns heading hierarchy for a specific file). These verify the index structure is correct end-to-end.",
      "acceptance_criteria": [
        "E2E test calls get_overview after switching to fixture docs and asserts: output contains all fixture file names, output contains expected section titles — verify: string matching",
        "E2E test calls get_file_toc with a known fixture filename and asserts heading hierarchy matches expected — verify: test",
        "get_file_toc with non-existent filename returns error message — verify: negative test",
        "mcp-server/src/__tests__/e2e-tools.test.ts passes — verify: npm test"
      ],
      "passes": true
    },
    {
      "group": "MCP-E2E-Integration",
      "feature": "E2E test: find_code_examples tool",
      "description": "Add E2E test for find_code_examples that verifies code blocks are correctly indexed and searchable. Fixture docs must contain code blocks in multiple languages.",
      "acceptance_criteria": [
        "Fixture .md files contain code blocks in at least 3 languages (javascript, python, bash) — verify: fixture inspection",
        "E2E test calls find_code_examples with query matching a known code snippet and asserts result contains the expected code — verify: test",
        "E2E test filters by language (e.g., language='python') and asserts only Python blocks returned — verify: test",
        "E2E test with non-matching query returns 'No code examples found' — verify: negative test",
        "mcp-server/src/__tests__/e2e-code.test.ts passes — verify: npm test"
      ],
      "passes": true
    },
    {
      "group": "MCP-E2E-Integration",
      "feature": "CI pipeline configuration for automated test runs",
      "description": "Create a GitHub Actions workflow (.github/workflows/test.yml) that runs both Python and TypeScript tests on push and PR. Installs dependencies, builds the MCP server, and runs all test suites. Fails the build if any test fails. No secrets needed (all tests use fixtures, no LLM calls).",
      "acceptance_criteria": [
        ".github/workflows/test.yml exists with jobs for Python (pytest) and TypeScript (vitest) — verify: YAML valid",
        "Python job: installs requirements.txt, runs pytest scraper/tests/ — verify: job steps",
        "TypeScript job: npm install, npm run build, npm test — verify: job steps",
        "Both jobs run on ubuntu-latest with Node 18 and Python 3.11 — verify: matrix config",
        "Workflow triggers on push to main and on pull_request — verify: on: config",
        "No secrets or API keys needed — verify: no env secrets in workflow"
      ],
      "passes": true
    }
  ]
}
